{
    "origin_link": "https://nlp.lab.uic.edu/nlp-research/human-robot-interaction/",
    "title": "Human-Robot Interaction | Natural Language Processing Laboratory | University of Illinois at Chicago",
    "contents": "               Skip to the content of this page ,  the main menu , the secondary menu , the site search form , the site home page .           Natural Language Processing Laboratory     Search the site     Toggle Menu      Search                  Natural Language Processing Laboratory      Natural Language Processing Laboratory   Main Menu    Research           Methodology and Foundational Work    NL for Educational Technology    Summarization for Entertainment and Healthcare    Human-Robot Interaction         People    Publications    Resources    Photos    News     Eyebrow menu    Computer Science    College of Engineering    Contact    UIC menu    UIC.edu    Campus Map       Search               View Menu           Breadcrumbs   Natural Language Processing Laboratory    Research    Human-Robot Interaction        Human-Robot Interaction       Human-robot interaction      Image: Wikipedia    In the last few years, the RoboHelper project (supported by NSF award IIS 0905593) has explored the development of robots tailored to the needs of the elderly ( Di Eugenio et al., 2010a ). We collected the multimodal ELDERLY-AT-HOME corpus, where one assistant collaborates with an elderly person in performing Activities of Daily Living (ADLs). The project has focused on building a multimodal interface for communication between the elderly person and the robot, since our data collection confirms that beyond language, gestures and haptic actions (gestures that involve touch) are pervasive in this sort of interaction. The corpus has been annotated for a variety of information and will be made available in due course. We have developed a multimodal dialogue manager that performs multimodal reference resolution ( Chen & Di Eugenio, 2012 ), models the fact that these interactions comprise not only dialogue acts but also physical actions, and predicts the next dialogue act on the basis of the preceding multimodal signals (Chen & Di Eugenio, 2013).          Research           Methodology and Foundational Work    NL for Educational Technology    Summarization for Entertainment and Healthcare    Human-Robot Interaction                    ",
    "outlinks": [
        "https://library.uic.edu/",
        "https://nlp.lab.uic.edu/publications/",
        "https://uic.edu/",
        "https://engineering.uic.edu/",
        "https://nlp.lab.uic.edu/nlp-research/methodology-and-foundational-work/",
        "https://nlp.lab.uic.edu/news-2/",
        "https://nlp.lab.uic.edu/resources/contact/",
        "https://nlp.lab.uic.edu/resources/",
        "https://nlp.lab.uic.edu/nlp-research/summarization-for-entertainment-and-for-health-care/",
        "https://nlp.lab.uic.edu/people/",
        "https://nlp.lab.uic.edu/nlp-research/nl-for-educational-technology/",
        "https://uic.edu/about/job-opportunities",
        "https://today.uic.edu/events",
        "https://catalog.uic.edu/ucat/academic-calendar/",
        "https://nlp.lab.uic.edu/nlp-research/",
        "https://nlp.lab.uic.edu/",
        "https://ready.uic.edu/digital-materials/uic-safe-mobile-app/",
        "https://dos.uic.edu/student-veterans-affairs/",
        "https://uihealth.uic.edu/",
        "https://maps.uic.edu/",
        "https://www.uic.edu/apps/departments-az/search",
        "https://emergency.uic.edu/",
        "https://nlp.lab.uic.edu/photos/",
        "https://disabilityresources.uic.edu/",
        "https://www.cs.uic.edu/",
        "https://today.uic.edu/"
    ]
}